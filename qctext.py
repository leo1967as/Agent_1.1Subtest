import os
import requests
import json
import sys
import re
import logging
import time
import argparse
from typing import Optional, Dict, List
from dotenv import load_dotenv
from pydantic import BaseModel, ValidationError, Field
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Log ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

# --- 2. ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå ---
try:
    import config
except ImportError:
    logging.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå config.py ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥")
    sys.exit(1)

# --- 3. Pydantic Models ---
class Court(BaseModel):
    name: str
    role: str

class Party(BaseModel):
    name: str
    role: str

class LegalCase(BaseModel):
    document_type: str
    # Pydantic Model ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô str ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏°‡∏≠
    case_number: str 
    involved_courts: List[Court]
    parties: List[Party]
    referenced_laws: List[str]
    case_background_full: Optional[str] = Field(default=None)
    plaintiffs_argument_full: Optional[str] = Field(default=None)
    defendants_argument_full: Optional[str] = Field(default=None)
    committee_reasoning_full: Optional[str] = Field(default=None)
    final_decision: Optional[str] = Field(default=None)

# --- 4. ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API (‡∏°‡∏µ Retry Logic) ---
class OpenRouterConnector:
    def __init__(self, api_key: str):
        if not api_key: raise ValueError("!!! ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á: ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î OPENROUTER_API_KEY ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env")
        self.api_key = api_key
        self.headers = {"Authorization": f"Bearer {self.api_key}", "HTTP-Referer": config.YOUR_SITE_URL, "X-Title": config.YOUR_APP_NAME, "Content-Type": "application/json"}
        self.session = requests.Session()
        retry_strategy = Retry(
            total=5,
            backoff_factor=2,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["POST"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("https://", adapter)
        self.session.mount("http://", adapter)

    def get_completion(self, prompt: str) -> Optional[str]:
        timeout = getattr(config, 'API_TIMEOUT', 120)
        model_name = getattr(config, 'MODEL_NAME', 'meta-llama/llama-3.1-70b-instruct')
        payload = {
            "model": model_name, "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.0, "top_p": 1.0, "max_tokens": 8192
        }
        try:
            response = self.session.post(url=config.OPENROUTER_API_URL, headers=self.headers, json=payload, timeout=timeout)
            response.raise_for_status()
            result = response.json()
            return result.get('choices', [{}])[0].get('message', {}).get('content')
        except requests.exceptions.RequestException as e:
            logging.error(f"‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡∏ñ‡∏≤‡∏ß‡∏£‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á: {e}")
            return None
        except (KeyError, IndexError, json.JSONDecodeError) as e:
            logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• JSON ‡∏à‡∏≤‡∏Å API ‡πÑ‡∏î‡πâ: {e}")
            if 'response' in locals(): logging.error(f"--- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö ---\n{response.text}\n--------------------")
            return None

# --- 5. ‡∏Ñ‡∏•‡∏≤‡∏™‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ---
class LegalCaseProcessor:
    def __init__(self, connector: OpenRouterConnector):
        self.connector = connector

    def _preprocess_text(self, text: str) -> str:
        processed_text = re.sub(r'---\s*Page\s*\d+\s*---', '', text)
        processed_text = re.sub(r'\s{2,}', ' ', processed_text).strip()
        return processed_text

    def extract_data_for_single_case(self, single_case_text: str) -> Optional[dict]:
        clean_text = self._preprocess_text(single_case_text)
        prompt = f"""
[SYSTEM ROLE]
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ Automated Data Extraction Engine ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á ‡∏ñ‡∏π‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÑ‡∏ó‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Structured JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå ‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡πà‡∏á‡∏Ñ‡∏£‡∏±‡∏î 100%

[MISSION]
‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:
1.  **Analyze**: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå "Raw Text Input" ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏°‡∏≤
2.  **Extract**: ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° "Schema Definition & Extraction Logic" ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
3.  **Format**: ‡∏™‡∏£‡πâ‡∏≤‡∏á JSON Object ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏° "Critical Output Rules"
4.  **Validate**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö "Final Validation Checklist" ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡∏°‡∏≠‡∏ö

---
[RAW TEXT INPUT]
\"\"\"
{clean_text}
\"\"\"

---
[SCHEMA DEFINITION & EXTRACTION LOGIC]
‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á JSON Object ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Logic ‡∏Å‡∏≤‡∏£‡∏™‡∏Å‡∏±‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

- **"document_type"**: (string) ‡∏™‡∏Å‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡πÄ‡∏ä‡πà‡∏ô "‡∏Ñ‡∏≥‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤‡∏®‡∏≤‡∏•‡∏é‡∏µ‡∏Å‡∏≤", "‡∏Ñ‡∏≥‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡∏ä‡∏µ‡πâ‡∏Ç‡∏≤‡∏î‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏®‡∏≤‡∏•")
- **"case_number"**: (string | null) ‡∏™‡∏Å‡∏±‡∏î‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (‡πÄ‡∏ä‡πà‡∏ô "‡∏Ñ‡∏î‡∏µ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÅ‡∏î‡∏á‡∏ó‡∏µ‡πà ‡∏≠.1234/2567" ‡∏´‡∏£‡∏∑‡∏≠ "99/2560") **‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏ß‡πâ** ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏î‡∏µ‡πÉ‡∏î‡πÜ ‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô `null`
- **"involved_courts"**: (array of objects) ‡∏™‡∏Å‡∏±‡∏î‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏®‡∏≤‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á ‡πÅ‡∏ï‡πà‡∏•‡∏∞ object ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ `{{ "name": "...", "role": "..." }}` ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà `[]`
- **"parties"**: (array of objects) ‡∏™‡∏Å‡∏±‡∏î‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏π‡πà‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÇ‡∏à‡∏ó‡∏Å‡πå, ‡∏à‡∏≥‡πÄ‡∏•‡∏¢, ‡∏ú‡∏π‡πâ‡∏£‡πâ‡∏≠‡∏á, ‡∏Ø‡∏•‡∏Ø) ‡πÅ‡∏ï‡πà‡∏•‡∏∞ object ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ `{{ "name": "...", "role": "..." }}` ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà `[]`
- **"referenced_laws"**: (array of strings) ‡∏™‡∏Å‡∏±‡∏î‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ "‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ö‡∏±‡∏ç‡∏ç‡∏±‡∏ï‡∏¥", "‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢", "‡∏£‡∏±‡∏ê‡∏ò‡∏£‡∏£‡∏°‡∏ô‡∏π‡∏ç" ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ñ‡∏∂‡∏á ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà `[]`
- **"case_background_full"**: (string | null) **[COPY-PASTE]** ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏î‡∏µ" ‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏±‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å‡πÜ ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á "‡πÇ‡∏à‡∏ó‡∏Å‡πå‡∏ü‡πâ‡∏≠‡∏á‡∏ß‡πà‡∏≤..."
- **"plaintiffs_argument_full"**: (string | null) **[COPY-PASTE]** ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ü‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏à‡∏ó‡∏Å‡πå ‡πÇ‡∏î‡∏¢‡∏°‡∏≠‡∏á‡∏´‡∏≤ Keyword ‡πÄ‡∏ä‡πà‡∏ô "‡πÇ‡∏à‡∏ó‡∏Å‡πå‡∏ü‡πâ‡∏≠‡∏á‡∏ß‡πà‡∏≤", "‡πÇ‡∏à‡∏ó‡∏Å‡πå‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏≠‡πâ‡∏≤‡∏á‡∏ß‡πà‡∏≤"
- **"defendants_argument_full"**: (string | null) **[COPY-PASTE]** ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏à‡∏≥‡πÄ‡∏•‡∏¢ ‡πÇ‡∏î‡∏¢‡∏°‡∏≠‡∏á‡∏´‡∏≤ Keyword ‡πÄ‡∏ä‡πà‡∏ô "‡∏à‡∏≥‡πÄ‡∏•‡∏¢‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏ß‡πà‡∏≤"
- **"committee_reasoning_full"**: (string | null) **[COPY-PASTE]** ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏≤‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ ‡πÇ‡∏î‡∏¢‡∏°‡∏≠‡∏á‡∏´‡∏≤ Keyword ‡πÄ‡∏ä‡πà‡∏ô "‡∏û‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡πâ‡∏ß", "‡∏®‡∏≤‡∏•‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤", "‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡∏ß‡πà‡∏≤" ‡πÑ‡∏õ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
- **"final_decision"**: (string | null) **[COPY-PASTE]** ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤ ‡πÇ‡∏î‡∏¢‡∏°‡∏≠‡∏á‡∏´‡∏≤ Keyword ‡πÄ‡∏ä‡πà‡∏ô "‡∏û‡∏¥‡∏û‡∏≤‡∏Å‡∏©‡∏≤‡∏ß‡πà‡∏≤", "‡∏à‡∏∂‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢"

---
[CRITICAL OUTPUT RULES]
1.  **VALID JSON ONLY**: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô JSON Object ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏° c√∫ ph√°p (syntax) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏î‡πÜ ‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢‡∏ö‡∏•‡πá‡∏≠‡∏Å `{{...}}` ‡πÇ‡∏î‡∏¢‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î
2.  **ESCAPE DOUBLE QUOTES**: ‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: ‡∏´‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏°‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô ‡πÉ‡∏ô‡∏ü‡∏¥‡∏•‡∏î‡πå `..._full`) ‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏û‡∏π‡∏î (`"`) ‡∏≠‡∏¢‡∏π‡πà‡∏†‡∏≤‡∏¢‡πÉ‡∏ô ‡∏Ñ‡∏∏‡∏ì **‡∏ï‡πâ‡∏≠‡∏á** ‡πÉ‡∏™‡πà backslash (`\\`) ‡πÑ‡∏ß‡πâ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏™‡∏°‡∏≠ (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô `\\"`) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á JSON ‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢
3.  **HANDLE MISSING DATA**: ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ü‡∏¥‡∏•‡∏î‡πå‡πÉ‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô `null` (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö string) ‡∏´‡∏£‡∏∑‡∏≠ `[]` (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö array) ‡∏≠‡∏¢‡πà‡∏≤‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏∞‡∏ó‡∏¥‡πâ‡∏á‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏õ
4.  **NO SUMMARIZATION**: ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡∏∏‡∏õ, ‡∏¢‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ó‡∏µ‡πà‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ `_full` ‡πÇ‡∏î‡∏¢‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î ‡πÉ‡∏´‡πâ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏°‡∏≤‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡∏Ñ‡∏≥

---
[FINAL VALIDATION CHECKLIST]
‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡∏à‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏≤‡∏° Checklist ‡∏ô‡∏µ‡πâ:
- [ ] ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Å `{{...}}` ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?
- [ ] ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ `"` ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏†‡∏≤‡∏¢‡πÉ‡∏ô value ‡∏Ç‡∏≠‡∏á string ‡∏ñ‡∏π‡∏Å escape ‡πÄ‡∏õ‡πá‡∏ô `\\"` ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?
- [ ] ‡∏ó‡∏∏‡∏Å‡∏ü‡∏¥‡∏•‡∏î‡πå‡πÉ‡∏ô Schema ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ü‡∏¥‡∏•‡∏î‡πå‡πÑ‡∏´‡∏ô‡∏´‡∏≤‡∏¢‡πÑ‡∏õ)
- [ ] ‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏ñ‡∏π‡∏Å‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô `null` ‡∏´‡∏£‡∏∑‡∏≠ `[]` ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡∏à‡∏á‡∏™‡πà‡∏á‡∏°‡∏≠‡∏ö JSON Object ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
"""
        llm_response_str = self.connector.get_completion(prompt)
        if not llm_response_str: return None
        try:
            json_match = re.search(r'\{.*\}', llm_response_str, re.DOTALL)
            if not json_match:
                logging.error(f"AI ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô JSON (‡πÑ‡∏°‡πà‡∏û‡∏ö JSON block)\n--- ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ---\n{llm_response_str}\n---")
                return None
            return json.loads(json_match.group(0))
        except json.JSONDecodeError as e:
            logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á JSON block ‡∏ó‡∏µ‡πà‡∏™‡∏Å‡∏±‡∏î‡∏°‡∏≤‡πÑ‡∏î‡πâ: {e}"); return None

# --- 6. Worker Function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡∏Ç‡∏ô‡∏≤‡∏ô ---
def process_case_worker(case_data: tuple) -> Dict:
    index, total, single_case_text, processor, output_dir = case_data
    
    case_number_pattern = re.compile(r'.*?\d+/\d{4}')
    case_id_pattern = re.compile(r'(\d+/\d{4})')
    
    match = case_id_pattern.search(single_case_text)
    if not match:
        return {"status": "skipped_no_id"}
        
    case_id_for_filename = match.group(1).replace('/', '-')
    case_id_for_fallback = match.group(1)
    
    output_filename = os.path.join(output_dir, f"{case_id_for_filename}.json")
    
    json_data = processor.extract_data_for_single_case(single_case_text)
    
    if json_data:
        ai_case_number = json_data.get("case_number")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á case_number ‡∏ó‡∏µ‡πà AI ‡πÉ‡∏´‡πâ‡∏°‡∏≤
        is_valid = isinstance(ai_case_number, str) and case_number_pattern.fullmatch(ai_case_number)
        
        if not is_valid:
            logging.warning(f"‡∏Ñ‡∏î‡∏µ {case_id_for_filename}: AI ‡πÉ‡∏´‡πâ case_number ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ('{ai_case_number}'). ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ fallback '{case_id_for_fallback}' ‡πÅ‡∏ó‡∏ô")
            json_data['case_number'] = case_id_for_fallback
        
        try:
            LegalCase.model_validate(json_data)
            with open(output_filename, "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=4)
            return {"status": "success", "case_number": case_id_for_filename}
        except ValidationError as e:
            logging.error(f"‡∏Ñ‡∏î‡∏µ {case_id_for_filename}: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå (Pydantic Error) - {e}")
            return {"status": "failed", "case_number": case_id_for_filename}
    else:
        logging.error(f"‡∏Ñ‡∏î‡∏µ {case_id_for_filename}: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• JSON ‡∏à‡∏≤‡∏Å AI")
        return {"status": "failed", "case_number": case_id_for_filename}

# --- 7. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ---

def run_processing(args, output_dir):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå .md ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API"""
    logging.info("--- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÇ‡∏´‡∏°‡∏î‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå .md ---")
    api_key = os.getenv("OPENROUTER_API_KEY")
    try:
        connector = OpenRouterConnector(api_key)
        processor = LegalCaseProcessor(connector)
    except ValueError as e: 
        logging.error(e); sys.exit(1)

    input_dir = "db_messymd"
    if not os.path.isdir(input_dir):
        logging.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Input: '{input_dir}'")
        return

    existing_case_ids = set()
    if not args.force:
        logging.info(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πÅ‡∏Å‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô '{output_dir}'...")
        for filename in os.listdir(output_dir):
            if filename.endswith(".json"):
                existing_case_ids.add(filename.replace('.json', '').replace('-', '/'))
        logging.info(f"‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {len(existing_case_ids)} ‡∏Ñ‡∏î‡∏µ ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏°")
    else:
        logging.warning("‡πÇ‡∏´‡∏°‡∏î --force: ‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏î‡∏µ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")

    def natural_sort_key(s):
        return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]

    all_raw_text = ""
    md_files = [f for f in os.listdir(input_dir) if f.endswith(".md")]
    if not md_files:
        logging.warning(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå .md ‡πÉ‡∏ô '{input_dir}'"); return

    logging.info(f"‡∏û‡∏ö {len(md_files)} ‡πÑ‡∏ü‡∏•‡πå .md. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    for filename in sorted(md_files, key=natural_sort_key):
        try:
            with open(os.path.join(input_dir, filename), "r", encoding="utf-8") as f:
                all_raw_text += f.read() + "\n___________________________\n"
        except Exception as e:
            logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏≠‡πà‡∏≤‡∏ô '{filename}': {e}")
    logging.info("‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå .md ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß")

    all_cases_in_files = all_raw_text.split("___________________________")
    case_pattern = re.compile(r'(\d+/\d{4})')
    cases_to_process = []
    
    logging.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
    for case_text in all_cases_in_files:
        if not case_text.strip(): continue
        match = case_pattern.search(case_text)
        if match:
            if match.group(1) not in existing_case_ids:
                cases_to_process.append(case_text.strip())
    
    if not cases_to_process:
        logging.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏î‡∏µ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
        return

    logging.info(f"‡∏û‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ñ‡∏î‡∏µ‡πÉ‡∏´‡∏°‡πà {len(cases_to_process)} ‡∏Ñ‡∏î‡∏µ. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏Ç‡∏ô‡∏≤‡∏ô...")
    tasks = [(i + 1, len(cases_to_process), text, processor, output_dir) for i, text in enumerate(cases_to_process)]
    counts = {"success": 0, "failed": 0, "skipped_no_id": 0}
    max_workers = min(16, (os.cpu_count() or 1) + 4)
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_task = {executor.submit(process_case_worker, task): task for task in tasks}
        for future in tqdm(as_completed(future_to_task), total=len(tasks), desc="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏î‡∏µ‡πÉ‡∏´‡∏°‡πà"):
            try:
                result = future.result()
                if result and result.get("status") in counts:
                    counts[result["status"]] += 1
            except Exception as exc:
                logging.error(f'‡∏Ñ‡∏î‡∏µ‡∏ó‡∏µ‡πà {future_to_task[future][0]} ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á: {exc}')
                counts["failed"] += 1
    
    logging.info("--- ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ ---")
    logging.info(f"‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà): {counts['success']} ‡∏Ñ‡∏î‡∏µ")
    logging.info(f"‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {counts['failed']} ‡∏Ñ‡∏î‡∏µ")
    logging.info(f"‡∏Ç‡πâ‡∏≤‡∏° (‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏î‡∏µ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠): {counts['skipped_no_id']} ‡∏Ñ‡∏î‡∏µ")

def run_verification_and_repair(output_dir):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ã‡πà‡∏≠‡∏°‡πÅ‡∏ã‡∏° case_number ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    logging.info("--- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÇ‡∏´‡∏°‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ã‡πà‡∏≠‡∏°‡πÅ‡∏ã‡∏°‡πÑ‡∏ü‡∏•‡πå JSON ---")
    
    files_to_check = [f for f in os.listdir(output_dir) if f.endswith(".json") and f != "_ALL_CASES_COMBINED.json"]
    if not files_to_check:
        logging.warning(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏ô '{output_dir}'")
        return

    logging.info(f"‡∏û‡∏ö {len(files_to_check)} ‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö...")
    
    validation_pattern = re.compile(r'.*?\d+/\d{4}')
    repaired_count = 0
    valid_count = 0
    
    for filename in tqdm(files_to_check, desc="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå JSON"):
        filepath = os.path.join(output_dir, filename)
        try:
            with open(filepath, 'r+', encoding='utf-8') as f:
                data = json.load(f)
                current_case_number = data.get("case_number", "")

                if isinstance(current_case_number, str) and validation_pattern.fullmatch(current_case_number):
                    valid_count += 1
                    continue
                
                new_case_number = filename.replace('.json', '').replace('-', '/')
                data['case_number'] = new_case_number
                
                f.seek(0)
                json.dump(data, f, ensure_ascii=False, indent=4)
                f.truncate()
                repaired_count += 1

        except (json.JSONDecodeError, IOError) as e:
            logging.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå '{filename}': {e}")
    
    logging.info("--- ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ---")
    logging.info(f"‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß: {valid_count} ‡πÑ‡∏ü‡∏•‡πå")
    logging.info(f"‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ã‡πà‡∏≠‡∏°‡πÅ‡∏ã‡∏° case_number: {repaired_count} ‡πÑ‡∏ü‡∏•‡πå")

def update_combined_file(output_dir):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå _ALL_CASES_COMBINED.json ‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏™‡∏°‡∏≠"""
    logging.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏ß‡∏° _ALL_CASES_COMBINED.json...")
    all_successful_cases = []
    combined_filename_leaf = "_ALL_CASES_COMBINED.json"
    
    def natural_sort_key(s):
        return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s.replace(".json", ""))]

    file_list = [f for f in os.listdir(output_dir) if f.endswith(".json") and f != combined_filename_leaf]

    for filename in sorted(file_list, key=natural_sort_key):
        try:
            filepath = os.path.join(output_dir, filename)
            with open(filepath, 'r', encoding='utf-8') as f:
                if os.path.getsize(filepath) > 0:
                    all_successful_cases.append(json.load(f))
                else:
                    logging.warning(f"‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ '{filename}' ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á")
        except (json.JSONDecodeError, IOError) as e:
            logging.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô '{filename}' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡∏°‡∏≤‡∏£‡∏ß‡∏°‡πÑ‡∏î‡πâ: {e}")

    if all_successful_cases:
        combined_filepath = os.path.join(output_dir, combined_filename_leaf)
        with open(combined_filepath, "w", encoding="utf-8") as f:
            json.dump(all_successful_cases, f, ensure_ascii=False, indent=4)
        logging.info(f"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏ß‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(all_successful_cases)} ‡∏Ñ‡∏î‡∏µ")

def main():
    parser = argparse.ArgumentParser(description="‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢")
    parser.add_argument('--force', action='store_true', help='‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏î‡∏µ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î')
    parser.add_argument('--verify-only', action='store_true', help='‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ã‡πà‡∏≠‡∏°‡πÅ‡∏ã‡∏°‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô')
    args = parser.parse_args()

    start_time = time.time()
    load_dotenv()
    output_dir = "processed_cases"
    os.makedirs(output_dir, exist_ok=True)

    if args.verify_only:
        run_verification_and_repair(output_dir)
    else:
        run_processing(args, output_dir)
        run_verification_and_repair(output_dir) # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ã‡πâ‡∏≥‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à
    
    update_combined_file(output_dir)

    end_time = time.time()
    logging.info(f"üéâ ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤: {end_time - start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

if __name__ == "__main__":
    main()