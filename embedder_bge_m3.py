# embedder_bge_m3.py
import os
import json
import logging
import time
import torch
import numpy as np
from typing import List, Dict
from sentence_transformers import SentenceTransformer
from pydantic import BaseModel, ValidationError
from tqdm import tqdm

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Log ‡πÅ‡∏•‡∏∞ Configuration ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

# --- Configuration ---
MODEL_NAME = "BAAI/bge-m3"
INPUT_JSON_PATH = "processed_cases/_ALL_CASES_COMBINED.json"
OUTPUT_PICKLE_PATH = "embeddings_bge_m3.pkl" # .pkl ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö NumPy arrays
BATCH_SIZE = 128 # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏Ç‡∏ô‡∏≤‡∏î VRAM ‡∏Ç‡∏≠‡∏á GPU (‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ä‡πâ VRAM ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô)

# --- 2. Pydantic Models ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Input ---
# ‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ
class Court(BaseModel):
    name: str
    role: str

class Party(BaseModel):
    name: str
    role: str

class LegalCase(BaseModel):
    document_type: str
    case_number: str
    involved_courts: List[Court]
    parties: List[Party]
    referenced_laws: List[str]
    case_background_full: str | None
    plaintiffs_argument_full: str | None
    defendants_argument_full: str | None
    committee_reasoning_full: str | None
    final_decision: str | None

# --- 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
def load_and_validate_cases(filepath: str) -> List[LegalCase]:
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢ Pydantic"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # --- START OF THE PROPOSED FIX ---
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô List ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if not isinstance(data, list):
            logging.error(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå '{filepath}' ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö List ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏î‡∏µ")
            return []

        case_list = []
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô List ‡∏ã‡πâ‡∏≠‡∏ô List ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ Flatten
        if len(data) > 0 and isinstance(data[0], list):
            logging.warning(f"‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö List ‡∏ã‡πâ‡∏≠‡∏ô List ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå '{filepath}'. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Flattening)...")
            # ‡πÉ‡∏ä‡πâ list comprehension ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏µ‡πà list ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô list ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            case_list = [case for sublist in data for case in sublist]
        else:
            # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô List ‡∏Ç‡∏≠‡∏á Dictionary ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
            case_list = data
        # --- END OF THE PROPOSED FIX ---

        validated_cases = [LegalCase.model_validate(case) for case in case_list]
        logging.info(f"‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(validated_cases)} ‡∏Ñ‡∏î‡∏µ")
        return validated_cases
    except FileNotFoundError:
        logging.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Input: '{filepath}' ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Å‡πà‡∏≠‡∏ô")
        return []
    except ValidationError as e:
        logging.error(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î: {e}")
        return []
    except Exception as e:
        logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡∏Ç‡∏ì‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå: {e}")
        return []
    
def prepare_texts_for_embedding(cases: List[LegalCase]) -> tuple[List[str], List[str]]:
    """
    ‡∏£‡∏ß‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏î‡∏µ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ Embedding
    """
    all_texts = []
    all_case_numbers = []
    for case in cases:
        # ‡∏£‡∏ß‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
        full_text = (
            f"‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏î‡∏µ: {case.case_number}\n\n"
            f"‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏î‡∏µ:\n{case.case_background_full or '‡πÑ‡∏°‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'}\n\n"
            f"‡∏Ç‡πâ‡∏≠‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏≠‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏à‡∏ó‡∏Å‡πå:\n{case.plaintiffs_argument_full or '‡πÑ‡∏°‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'}\n\n"
            f"‡∏Ç‡πâ‡∏≠‡∏ï‡πà‡∏≠‡∏™‡∏π‡πâ‡∏Ç‡∏≠‡∏á‡∏à‡∏≥‡πÄ‡∏•‡∏¢:\n{case.defendants_argument_full or '‡πÑ‡∏°‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'}\n\n"
            f"‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ì‡∏∞‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£:\n{case.committee_reasoning_full or '‡πÑ‡∏°‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'}\n\n"
            f"‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢:\n{case.final_decision or '‡πÑ‡∏°‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'}"
        )
        all_texts.append(full_text)
        all_case_numbers.append(case.case_number)
    logging.info(f"‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Embedding ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(all_texts)} ‡∏ä‡∏∏‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
    return all_texts, all_case_numbers

# --- 4. ‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ---
def main():
    # --- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö CUDA ---
    if not torch.cuda.is_available():
        logging.error("‡πÑ‡∏°‡πà‡∏û‡∏ö CUDA device! ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ GPU ‡∏Ç‡∏≠‡∏á NVIDIA ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
        return

    logging.info(f"‡∏û‡∏ö CUDA device: {torch.cuda.get_device_name(0)}")

    # --- 1. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
    legal_cases = load_and_validate_cases(INPUT_JSON_PATH)
    if not legal_cases:
        logging.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        return
    
    texts_to_embed, case_numbers = prepare_texts_for_embedding(legal_cases)

    # --- 2. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• bge-m3 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ---
    logging.info(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• '{MODEL_NAME}' ‡∏•‡∏á‡∏ö‡∏ô CUDA...")
    
    # *** ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å (‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡πá‡∏ß) ***
    # 1. device='cuda': ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ö‡∏ô GPU
    # 2. torch_dtype=torch.float16: ‡πÉ‡∏ä‡πâ 16-bit precision ‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ VRAM ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏ö‡∏ô Tensor Cores
    # 3. trust_remote_code=True: ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏≤‡∏á‡∏ï‡∏±‡∏ß ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á bge-m3
    # 4. Flash Attention 2: ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á `flash-attn` ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ `sentence-transformers`
    #    ‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡πâ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡∏≠‡∏µ‡∏Å 2-4 ‡πÄ‡∏ó‡πà‡∏≤!
    try:
        model = SentenceTransformer(
            MODEL_NAME,
            device='cuda',
            # torch_dtype=torch.float16,
            trust_remote_code=True
        )
        logging.info("‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
    except Exception as e:
        logging.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {e}")
        logging.error("‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô Cache ‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢")
        return

    # --- 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ---
    logging.info(f"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {len(texts_to_embed)} ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (Batch Size: {BATCH_SIZE})...")
    start_time = time.time()

    embeddings = model.encode(
        texts_to_embed,
        batch_size=BATCH_SIZE,
        show_progress_bar=True,
        normalize_embeddings=True # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡πÄ‡∏™‡∏°‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö bge models
    )

    end_time = time.time()
    processing_time = end_time - start_time
    docs_per_second = len(texts_to_embed) / processing_time

    logging.info("‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!")
    logging.info(f"‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á Embeddings: {embeddings.shape}") # ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£, 1024) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö bge-m3
    logging.info(f"‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {processing_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ({docs_per_second:.2f} ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£/‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)")

    # --- 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ---
    logging.info(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå '{OUTPUT_PICKLE_PATH}'...")
    
    # ‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Dictionary ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ
    output_data = {
        "case_numbers": case_numbers,
        "texts": texts_to_embed,
        "embeddings": embeddings
    }

    import pickle
    with open(OUTPUT_PICKLE_PATH, "wb") as f_out:
        pickle.dump(output_data, f_out)

    logging.info("üéâ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå")

if __name__ == "__main__":
    main()